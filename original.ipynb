{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mu7D5Qk26qau"
   },
   "source": [
    "# This code is for HOS using multilingual Embeddings for three Dravidian CodeMix languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpTvFQ5b6qaw"
   },
   "source": [
    "## Packages to be installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4183,
     "status": "ok",
     "timestamp": 1734239310222,
     "user": {
      "displayName": "Sahayatrika",
      "userId": "17491921574162570429"
     },
     "user_tz": -330
    },
    "id": "_21RJfmP6qax",
    "outputId": "6d9a2c41-27fe-47fa-f93c-88549fc7fda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 3.2.1\n",
      "    Uninstalling sentence-transformers-3.2.1:\n",
      "      Successfully uninstalled sentence-transformers-3.2.1\n",
      "Successfully installed sentence-transformers-3.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkPO7PCu6qax"
   },
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iFqpZRoL6qax"
   },
   "outputs": [],
   "source": [
    "# packages\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.metrics import (precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLA2Lm6p6qay"
   },
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgm2SOJ76qay"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"malayalam_offensive_train.csv\")\n",
    "test = pd.read_csv(\"mal_full_offensive_test.csv\",header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tp1tRCi56qay"
   },
   "source": [
    "### Sperate the train and test senetnecs and labels to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "executionInfo": {
     "elapsed": 422,
     "status": "error",
     "timestamp": 1734239363754,
     "user": {
      "displayName": "Sahayatrika",
      "userId": "17491921574162570429"
     },
     "user_tz": -330
    },
    "id": "UBt-GEIo6qay",
    "outputId": "854f1d07-ad90-478d-8ad8-0052a0c646cd"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3df2fbce403d>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_label_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_sent_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_label_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "train_sent_m=[]\n",
    "train_label_m=[]\n",
    "test_sent_m = []\n",
    "test_label_m = []\n",
    "\n",
    "for i in train['0']:\n",
    "    train_sent_m.append(i.split('\\t')[0])\n",
    "    train_label_m.append(i.split('\\t')[1])\n",
    "\n",
    "for i in test[0]:\n",
    "    test_sent_m.append(i.split('\\t')[0])\n",
    "    test_label_m.append(i.split('\\t')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CHswCcC6qay"
   },
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejFik5aV6qay"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_labels_encoded = le.fit_transform(train_label_m)\n",
    "dev_labels_encoded = le.fit_transform(test_label_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMAY3sXH6qaz"
   },
   "source": [
    "### Get Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8zVPh-L6qaz"
   },
   "outputs": [],
   "source": [
    "trans_model = SentenceTransformer('bert-base-multilingual-cased')\n",
    "# here other multilingual embeddings can be loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3F5UtrR6qaz"
   },
   "outputs": [],
   "source": [
    "train_sentence_embeddings = trans_model.encode(train_sent_m)\n",
    "dev_sentence_embeddings = trans_model.encode(test_sent_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSHdkSld6qaz"
   },
   "source": [
    "### Weight calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoLb_NrD6qaz"
   },
   "outputs": [],
   "source": [
    "class_weights = sklearn.utils.class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_label_m),\n",
    "                                                 train_label_m)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVvhajrX6qaz"
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6rmzb5U6qaz"
   },
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y30Y49666qaz"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "class_weight = {0:0.22607331, 1:23.54117647 ,2:13.69505703 ,3:17.07014218 ,4:2.484}\n",
    "model = LogisticRegression(class_weight=class_weight)\n",
    "model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv\n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('Logistic_regression.csv')\n",
    "print(\"prediction saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeMdBTss6qaz"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mvMuJaS6qaz"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_LR.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2Drtez56qa0"
   },
   "source": [
    "### Naive Bayse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzy8JRtL6qa0"
   },
   "outputs": [],
   "source": [
    "# NAive Baise\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "model = GaussianNB()\n",
    "model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv\n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('Naive_baise.csv')\n",
    "print(\"prediction saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ib_GFXK46qa0"
   },
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSMiEtO16qa0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_NB.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcaqzijB6qa0"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STFztBME6qa0"
   },
   "outputs": [],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "class_weight = {0:0.22607331, 1:23.54117647 ,2:13.69505703 ,3:17.07014218 ,4:2.484}\n",
    "model = RandomForestClassifier(n_estimators=100, class_weight=class_weight)\n",
    "model = model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv\n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('RF.csv')\n",
    "print(\"prediction saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHVtTlL-6qa0"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsdj6akr6qa0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_RF.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQIwqwZ66qa0"
   },
   "source": [
    "## SVM RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiGl2iBL6qa0"
   },
   "outputs": [],
   "source": [
    "# SVM rbf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "class_weight = {0:0.22607331, 1:23.54117647 ,2:13.69505703 ,3:17.07014218 ,4:2.484}\n",
    "model = svm.SVC(kernel='rbf',C = 1000, class_weight =class_weight)\n",
    "model = model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv\n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('SVM_RBF.csv')\n",
    "print(\"prediction saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrFawbUw6qa1"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeItnXKp6qa1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_SVM_rbf.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUYk1Ag76qa1"
   },
   "source": [
    "## SVM Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDlxITz46qa1"
   },
   "outputs": [],
   "source": [
    "# SVM poly\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='poly',C = 1000)\n",
    "model = model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv\n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('SVM_poly_labse.csv')\n",
    "print(\"prediction saved\")\n",
    "\n",
    "#Save model\n",
    "import pickle\n",
    "# Save the trained model as a pickle string.\n",
    "pkl_filename = \"poly_labse.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSOWYnST6qa1"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyIvtLyc6qa1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot =True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_SVM_poly_labse.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMj47yZQ6qa1"
   },
   "source": [
    "## SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJO97UIE6qa1"
   },
   "outputs": [],
   "source": [
    "# SVM Linear\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='linear',C = 10)\n",
    "model = model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv\n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('SVM_linear_labse.csv')\n",
    "print(\"prediction saved\")\n",
    "\n",
    "#Save model\n",
    "import pickle\n",
    "# Save the trained model as a pickle string.\n",
    "pkl_filename = \"linear_labse.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhMitdAW6qa3"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tfHx75Fm6qa4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot =True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_SVM_linear_labse.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9Uu-zDR6qa4"
   },
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzxXWKnu6qa4"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(n_estimators=100)\n",
    "model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv\n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('Adaboost.csv')\n",
    "print(\"prediction saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2neXMJYu6qa4"
   },
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zlD6LXo6qa4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_adaboost.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHz4r3YZ6qa4"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yju37FLq6qa4"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(weights = 'distance')\n",
    "model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv\n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('KNN.csv')\n",
    "print(\"prediction saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfSvoqSV6qa4"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8-IYpa06qa4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "cfm= confusion_matrix(expected, predicted)\n",
    "classes = np.unique(train_label_m)\n",
    "\n",
    "df_cfm = pd.DataFrame(cfm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,5))\n",
    "cfm_plot = sn.heatmap(df_cfm, annot=True,  fmt='g')\n",
    "cfm_plot.figure.savefig(\"cfm_KNN.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOsST7aW6qa4"
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "haNpNBn-6qa5"
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "class_weight = {0:0.22607331, 1:23.54117647 ,2:13.69505703 ,3:17.07014218 ,4:2.484}\n",
    "model = DecisionTreeClassifier(class_weight=class_weight)\n",
    "model.fit(train_sentence_embeddings, train_labels_encoded)\n",
    "\n",
    "\n",
    "# make predictions\n",
    "expected = dev_labels_encoded\n",
    "predicted = model.predict(dev_sentence_embeddings)\n",
    "\n",
    "\n",
    "print(\"eval scores\")\n",
    "accuracy = accuracy_score(expected, predicted)\n",
    "recall = recall_score(expected, predicted , average=\"macro\")\n",
    "precision = precision_score(expected, predicted , average=\"macro\")\n",
    "f1 = f1_score(expected, predicted, average=\"macro\")\n",
    "\n",
    "print(\"macro\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.3f\" %accuracy)\n",
    "print(\"precision\")\n",
    "print(\"%.3f\" %precision)\n",
    "print(\"racall\")\n",
    "print(\"%.3f\" %recall)\n",
    "print(\"f1score\")\n",
    "print(\"%.3f\" %f1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Classification report\")\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "sklearn.metrics.classification_report(expected, predicted)\n",
    "target_names = ['Not_offensive', 'Offensive_Targeted_Insult_Group', 'Offensive_Targeted_Insult_Individual', 'Offensive_Untargetede', 'not-malayalam']\n",
    "print(classification_report(expected, predicted, target_names=target_names))\n",
    "\n",
    "\n",
    "#Saving the predictions\n",
    "import csv\n",
    "predictions = list(le.inverse_transform(predicted))\n",
    "classified_df = pd.DataFrame( {'tweets': test_sent_m, 'actual_label': test_label_m, 'predictions': predictions})\n",
    "classified_df.to_csv('DT.csv')\n",
    "print(\"prediction saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "280zcfE76qa5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERL11QNP6qa5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/Sreelakshmi-k/Hate-speech-Detection-from-CodeMix-Dravidian-Languages/blob/main/Code.ipynb",
     "timestamp": 1734192337399
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
